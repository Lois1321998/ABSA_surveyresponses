{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca951e39-fecc-4bf2-bbcf-0576faf2988f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from scipy.stats import shapiro, wilcoxon, binom_test\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542a18a5-c5d6-4a86-9315-dd2ccdd1436c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_f1_scores_aspects(data_dict):\n",
    "    f1_scores = []\n",
    "    for category, metrics in data_dict.items():\n",
    "        if category != 'micro avg' and category != 'macro avg' and category != 'weighted avg' and category != 'samples avg':\n",
    "            f1_scores.append(metrics['f1-score'])\n",
    "    return f1_scores\n",
    "\n",
    "\n",
    "def extract_f1_scores_sentiments(data_dict):\n",
    "    f1_scores = {}\n",
    "    for category, metrics in data_dict.items():\n",
    "        if category != 'accuracy' and category != 'macro avg' and category != 'weighted avg':\n",
    "            f1_scores[category] = metrics['f1-score']\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb7234-cf3e-4fcb-9f94-00dd017e8ccc",
   "metadata": {},
   "source": [
    "# SVM aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337db820-cbce-4b3c-b4fa-b5064fd3351e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            afspraken     1.0000    0.1739    0.2963        23\n",
      "         communicatie     0.5000    0.2000    0.2857        80\n",
      "              contact     0.5278    0.2754    0.3619        69\n",
      "persoonlijke aandacht     0.6299    0.5774    0.6025       168\n",
      " roosters en planning     0.8000    0.2667    0.4000        45\n",
      "              salaris     0.7667    0.3966    0.5227        58\n",
      "\n",
      "            micro avg     0.6310    0.3860    0.4790       443\n",
      "            macro avg     0.7041    0.3150    0.4115       443\n",
      "         weighted avg     0.6449    0.3860    0.4609       443\n",
      "          samples avg     0.3225    0.2958    0.2991       443\n",
      "\n",
      "(479, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "SVM_results_aspect = pd.read_csv(\"data/predictions/SVM_aspects_test.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(SVM_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(SVM_results_aspect['predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_SVM_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_SVM = extract_f1_scores_aspects(scores_SVM_aspects)\n",
    "shapiro(f1_scores_SVM)\n",
    "print(SVM_results_aspect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959f6a3-f82d-4f7b-bae3-ee9e6442cf65",
   "metadata": {},
   "source": [
    "# SVM sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb238b0c-50f9-41be-b35b-077f444364a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negatief     0.8937    0.9318    0.9124       352\n",
      "    positief     0.6842    0.5714    0.6228        91\n",
      "\n",
      "    accuracy                         0.8578       443\n",
      "   macro avg     0.7890    0.7516    0.7676       443\n",
      "weighted avg     0.8507    0.8578    0.8529       443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_results_sent = pd.read_csv(\"data/predictions/SVM_sentiments_test.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = SVM_results_sent['sentiment']\n",
    "y_pred = SVM_results_sent['predicted_sentiment']\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "output_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "SVM_scores_sentiments = extract_f1_scores_sentiments(output_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc75be-f97e-4da7-bfbd-2474831f1e45",
   "metadata": {},
   "source": [
    "# MLP aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a0d76f-a9d0-43fe-933c-54dc443a5dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "MLP_results_aspect = pd.read_csv(\"data/predictions/MLP_aspects_withoutDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(MLP_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(MLP_results_aspect['predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_MLP_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_MLP_asp = extract_f1_scores_aspects(scores_MLP_aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f806c58-a018-4533-9316-a4d7b115a77e",
   "metadata": {},
   "source": [
    "# MLP sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caae3e75-6498-45df-9c7f-7e7efc9a751f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLP_results_sentiment = pd.read_csv(\"data/predictions/MLP_sentiments_withoutDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = MLP_results_sentiment['sentiment']\n",
    "y_pred = MLP_results_sentiment['predictions']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_MLP_sent = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_MLP_sent = extract_f1_scores_sentiments(scores_MLP_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7aeb5-9ce2-4554-8914-23cd510df7e3",
   "metadata": {},
   "source": [
    "# BERTje zero aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa229af-e224-4359-8017-5e9537a7f3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8600451467268623"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERTjezero_results_aspect = pd.read_csv(\"data/predictions/BERTje_zeroshot_aspects_withoutDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(BERTjezero_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(BERTjezero_results_aspect['predicted_aspects'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_BERTjezero_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjezero_asp = extract_f1_scores_aspects(scores_BERTjezero_aspects)\n",
    "\n",
    "Counter(BERTjezero_results_aspect['predicted_aspects'])\n",
    "\n",
    "381/443"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50d0e7-ac81-4e33-857b-2862247d247b",
   "metadata": {},
   "source": [
    "# BERTje zero sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5816104d-72e4-420d-a426-90727761cc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BERTjezero_results_sentiment = pd.read_csv(\"data/predictions/BERTje_zeroshot_sentiments_withoutDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = BERTjezero_results_sentiment['sentiment']\n",
    "y_pred = BERTjezero_results_sentiment['predicted_sentiment']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_BERTjezero_sent = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjezero_sent = extract_f1_scores_sentiments(scores_BERTjezero_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d2827-b4cf-4a0d-b414-5587918c4d47",
   "metadata": {},
   "source": [
    "# RobBERT zero aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b56e315-a60e-448c-9306-a986734ee9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "RobBERTzero_results_aspect = pd.read_csv(\"data/predictions/RobBERT_zeroshot_aspects_withoutDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(RobBERTzero_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(RobBERTzero_results_aspect['predicted_aspects'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_RobBERTzero_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTzero_asp = extract_f1_scores_aspects(scores_RobBERTzero_aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a0ed2-6cec-4892-af97-4e64f183d93f",
   "metadata": {},
   "source": [
    "# RobBERT zero sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3323e1d-be1f-4337-af49-cf3c1c1529f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RobBERTzero_results_sentiment = pd.read_csv(\"data/predictions/RobBERT_zeroshot_sentiments_withoutDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = RobBERTzero_results_sentiment['sentiment']\n",
    "y_pred = RobBERTzero_results_sentiment['predicted_sentiment']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=3))\n",
    "scores_RobBERTzero_sent = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTzero_sent = extract_f1_scores_sentiments(scores_RobBERTzero_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435edcbf-a825-4648-8ab3-c9a9d23ddc1e",
   "metadata": {},
   "source": [
    "# BERTje few aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93479cd-4470-4bb3-9abb-b680b036e6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "BERTjefew_results_aspect = pd.read_csv(\"data/predictions/BERTje_fewshot_aspects_test_withoutDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(BERTjefew_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(BERTjefew_results_aspect['decoded_predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=3))\n",
    "scores_BERTjefew_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjefew_asp = extract_f1_scores_aspects(scores_BERTjefew_aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ca959-317a-46f2-8a3a-4049c0730c6a",
   "metadata": {},
   "source": [
    "# BERTje few sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7669b6df-4a7f-4905-8b4f-21dca8dbbd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BERTjefew_results_sentiment = pd.read_csv(\"data/predictions/BERTje_fewshot_sentiments_withoutDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = BERTjefew_results_sentiment['targets']\n",
    "y_pred = BERTjefew_results_sentiment['prediction']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_BERTjefew_sent = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjefew_sent = extract_f1_scores_sentiments(scores_BERTjefew_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b2fd3-7824-4bc5-ac72-c79717f2704b",
   "metadata": {},
   "source": [
    "## RobBERT few aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea88059-af2e-4297-9847-a17be45ad7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "RobBERTfew_results_aspect = pd.read_csv(\"data/predictions/RobBERT_fewshot_aspects_withoutDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(RobBERTfew_results_aspect['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(RobBERTfew_results_aspect['decoded_predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_RobBERTfew_aspects = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTfew_asp = extract_f1_scores_aspects(scores_RobBERTfew_aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360ee3c-d4fa-4706-9ebc-d4d07563ac91",
   "metadata": {},
   "source": [
    "# RobBERT few sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f1ee81-cf4e-4f43-abe6-18ed8160903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RobBERTfew_results_sentiment = pd.read_csv(\"data/predictions/RobBERT_fewshot_sentiments_withoutDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = RobBERTfew_results_sentiment['targets']\n",
    "y_pred = RobBERTfew_results_sentiment['predictions']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_RobBERTfew_sent = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTfew_sent = extract_f1_scores_sentiments(scores_RobBERTfew_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ab74f-8bf5-4244-b3cb-c94d80947a9f",
   "metadata": {},
   "source": [
    "# BERTje_few_aspects_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3f34da-12ef-48d3-b661-df6b464eada0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "BERTjefew_results_aspectDA = pd.read_csv(\"data/predictions/BERTje_fewshot_aspects_test_withDA.csv\", sep=';')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(BERTjefew_results_aspectDA['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(BERTjefew_results_aspectDA['decoded_predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, target_names=mlb.classes_, digits=4))\n",
    "scores_BERTjefew_aspectsDA = classification_report(y_true, y_pred, target_names=mlb.classes_, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjefew_aspDA = extract_f1_scores_aspects(scores_BERTjefew_aspectsDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fba11e-7cf3-45aa-bd90-7e5dd2e38150",
   "metadata": {},
   "source": [
    "# BERTje_few_sentiments_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd3e2fe-f632-44d3-a131-bc991d867246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BERTjefew_results_sentimentDA = pd.read_csv(\"data/predictions/BERTje_fewshot_sentiments_withDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = BERTjefew_results_sentimentDA['targets']\n",
    "y_pred = BERTjefew_results_sentimentDA['prediction']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_BERTjefew_sentDA = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_BERTjefew_sentDA = extract_f1_scores_sentiments(scores_BERTjefew_sentDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143876a6-0a3f-4862-aa90-f4dd86f27ca4",
   "metadata": {},
   "source": [
    "# RobBERT few aspects_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b302b6f7-a00a-4d75-95fb-35fe7a329ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'text', 'common_annotation', 'clean_annotation', 'onehot',\n",
      "       'predictions', 'decoded_predictions'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "RobBERTfew_results_aspectDA = pd.read_csv(\"data/predictions/RobBERT_fewshot_aspects_withDA.csv\", sep=';')\n",
    "print(RobBERTfew_results_aspectDA.columns)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(RobBERTfew_results_aspectDA['clean_annotation'].apply(lambda x: ast.literal_eval(x)))\n",
    "y_pred = mlb.fit_transform(RobBERTfew_results_aspectDA['decoded_predictions'].apply(lambda x: ast.literal_eval(x)))\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_RobBERTfew_aspectDA = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTfew_aspectDA = extract_f1_scores_aspects(scores_RobBERTfew_aspectDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171e5d8-fd9a-43fb-9839-b3a1e9ab1425",
   "metadata": {},
   "source": [
    "# RobBERT few sentiments_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71884db-6123-448d-b6da-406e7aa42c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RobBERTfew_results_sentimentDA = pd.read_csv(\"data/predictions/RobBERT_fewshot_sentiments_withDA.csv\", sep=';')\n",
    "\n",
    "\n",
    "y_true = RobBERTfew_results_sentimentDA['encoded_polarity']\n",
    "y_pred = RobBERTfew_results_sentimentDA['predictions']\n",
    "\n",
    "#print(classification_report(y_true, y_pred, digits=4))\n",
    "scores_RobBERTfew_sentDA = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "f1_scores_RobBERTfew_sentDA = extract_f1_scores_sentiments(scores_RobBERTfew_sentDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0394e7d-8956-42b1-a6ff-da6df1d3ea90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = RobBERTfew_results_aspect\n",
    "df['gold_label'] = df['clean_annotation'].apply(lambda x: ast.literal_eval(x)) \n",
    "df['RobBERTfew_label'] = df['decoded_predictions'].apply(lambda x: ast.literal_eval(x))\n",
    "df['BERTjefew_label'] = BERTjefew_results_aspect['decoded_predictions'].apply(lambda x: ast.literal_eval(x))\n",
    "df['SVM_label'] = SVM_results_aspect['predictions'].apply(lambda x: ast.literal_eval(x))\n",
    "df['MLP_label'] = MLP_results_aspect['predictions'].apply(lambda x: ast.literal_eval(x))\n",
    "df['RobBERTzero_label'] = RobBERTzero_results_aspect['predicted_aspects'].apply(lambda x: ast.literal_eval(x))\n",
    "df['BERTjezero_label'] = BERTjezero_results_aspect['predicted_aspects'].apply(lambda x: ast.literal_eval(x))\n",
    "df['RobBERT_fewDA_label'] = RobBERTfew_results_aspectDA['decoded_predictions'].apply(lambda x: ast.literal_eval(x))\n",
    "df['BERTje_fewDA_label'] = BERTjefew_results_aspectDA['decoded_predictions'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb023f9-ac77-480e-a9ac-31633b8fea71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_compare = ['RobBERTfew_label', 'SVM_label', 'BERTjefew_label', 'MLP_label', 'RobBERTzero_label',\n",
    "                      'BERTjezero_label', 'RobBERT_fewDA_label', 'BERTje_fewDA_label']\n",
    "convert_to_list = lambda x: list(x) if isinstance(x, tuple) else x\n",
    "\n",
    "# Iterate over the columns\n",
    "for column in columns_to_compare:\n",
    "    # Create a new column name by appending '_binary' to the original column name\n",
    "    new_column = column + '_binary'\n",
    "    # Compare the values in the column with the 'clean_annotation' column after converting tuples to lists\n",
    "    df[column] = df[column].apply(lambda x: list(x))\n",
    "    df[new_column] = (df[column].apply(lambda x: list(x) if isinstance(x, tuple) else x) == df['gold_label']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3232bc3-4531-4d0c-bec1-02532ada1203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=0.0, pvalue=3.8071669115004615e-59)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['RobBERTfew_label_binary'], df['RobBERTzero_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "283b8560-35ff-4d49-af60-d66e2e274537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3060.0, pvalue=5.220985924053902e-09)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['RobBERTfew_label_binary'], df['SVM_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faa4f513-c7b1-4544-8191-8bc5b3e76fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3818.0, pvalue=1.323195307423342e-08)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['RobBERTfew_label_binary'], df['MLP_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3681ff85-20a8-4d06-8c5d-c6d3ce699afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=2486.0, pvalue=0.023342202012890816)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['RobBERTfew_label_binary'], df['BERTjefew_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99a534-d0af-47ac-807c-8955bdd5a398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883166b8-52a3-4542-8398-0d3db2b394db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=120.5, pvalue=2.905893776313556e-53)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['BERTjefew_label_binary'], df['BERTjezero_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc5a368-d8b8-4060-8e30-c17f89e92f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3850.5, pvalue=8.88494191145669e-05)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['BERTjefew_label_binary'], df['SVM_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6653cefd-e88b-40a3-8a9c-5f35c354810c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3750.0, pvalue=5.963854882444082e-05)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['BERTjefew_label_binary'], df['MLP_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d18a0f95-8978-4448-a64a-873cc8f8f237",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=1085.0, pvalue=0.39939570366685395)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['BERTjefew_label_binary'], df['BERTje_fewDA_label_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ab99711-4b6b-413c-9ba2-7fe8fc173950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=887.5, pvalue=0.01682740948275685)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df['RobBERTfew_label_binary'], df['RobBERT_fewDA_label_binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f7e60-7d91-4605-a517-13d7efb104e0",
   "metadata": {},
   "source": [
    "# sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0415081-b077-46ed-bb8a-3948ed2d53ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sent = RobBERTfew_results_sentiment\n",
    "df_sent['gold_label'] = df_sent['sentiment']\n",
    "df_sent['RobBERTfew_label'] = df_sent['predictions']\n",
    "df_sent['BERTjefew_label'] = BERTjefew_results_sentiment['prediction']\n",
    "df_sent['SVM_label'] = SVM_results_sent['predicted_sentiment']\n",
    "df_sent['MLP_label'] = MLP_results_sentiment['predictions']\n",
    "df_sent['RobBERTzero_label'] = RobBERTzero_results_sentiment['predicted_sentiment']\n",
    "df_sent['BERTjezero_label'] = BERTjezero_results_sentiment['predicted_sentiment']\n",
    "df_sent['RobBERT_fewDA_label'] = RobBERTfew_results_sentimentDA['predictions']\n",
    "df_sent['BERTje_fewDA_label'] = BERTjefew_results_sentimentDA['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f828186-9a04-4b3e-a6cb-b4c87d85480d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobBERTfew_label\n",
      "SVM_label\n",
      "BERTjefew_label\n",
      "MLP_label\n",
      "RobBERTzero_label\n",
      "BERTjezero_label\n",
      "RobBERT_fewDA_label\n",
      "BERTje_fewDA_label\n"
     ]
    }
   ],
   "source": [
    "columns_to_compare = ['RobBERTfew_label', 'SVM_label', 'BERTjefew_label', 'MLP_label', 'RobBERTzero_label',\n",
    "                      'BERTjezero_label', 'RobBERT_fewDA_label', 'BERTje_fewDA_label']\n",
    "\n",
    "df_sent['gold_label'] = df_sent['gold_label'].replace({'negatief': 0, 'positief': 1})\n",
    "\n",
    "# Iterate over the columns\n",
    "for column in columns_to_compare:\n",
    "    print(column)\n",
    "    df_sent[column] = df_sent[column].replace({'negatief': 0, 'positief': 1}).astype(int)\n",
    "    # Create a new column name by appending '_binary' to the original column name\n",
    "    new_column = column + '_binary'\n",
    "    # Compare the values in the column with the 'gold_label' column\n",
    "    df_sent[new_column] = (df_sent[column] == df_sent['gold_label']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3efd0c22-551e-4fc1-9a30-1cff3eab78da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>common_annotation</th>\n",
       "      <th>clean_annotation</th>\n",
       "      <th>encoded_polarity</th>\n",
       "      <th>predictions</th>\n",
       "      <th>targets</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>...</th>\n",
       "      <th>RobBERT_fewDA_label</th>\n",
       "      <th>BERTje_fewDA_label</th>\n",
       "      <th>RobBERTfew_label_binary</th>\n",
       "      <th>SVM_label_binary</th>\n",
       "      <th>BERTjefew_label_binary</th>\n",
       "      <th>MLP_label_binary</th>\n",
       "      <th>RobBERTzero_label_binary</th>\n",
       "      <th>BERTjezero_label_binary</th>\n",
       "      <th>RobBERT_fewDA_label_binary</th>\n",
       "      <th>BERTje_fewDA_label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Betere verdeling van uren het verplicht stoppe...</td>\n",
       "      <td>roosters en planning</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['roosters-planning_NEG']</td>\n",
       "      <td>['roosters en planning']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Zou fijn zijn als ik bezoek zou krijgen van We...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['persoonlijke-aandacht_NEG']</td>\n",
       "      <td>['persoonlijke aandacht']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Meedenken carrire, voorstel betere functies, s...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['persoonlijke-aandacht_NEG', 'salaris_NEG']</td>\n",
       "      <td>['persoonlijke aandacht', 'salaris']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meedenken carrire, voorstel betere functies, s...</td>\n",
       "      <td>salaris</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['persoonlijke-aandacht_NEG', 'salaris_NEG']</td>\n",
       "      <td>['persoonlijke aandacht', 'salaris']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Beetje meer waardering zou top zijn met het ke...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['persoonlijke-aandacht_NEG']</td>\n",
       "      <td>['persoonlijke aandacht']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>560</td>\n",
       "      <td>Ik heb het idee dat nog heel veel intercedente...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['persoonlijke-aandacht_NEG']</td>\n",
       "      <td>['persoonlijke aandacht']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>561</td>\n",
       "      <td>Er mag wel meer uitgelegd worden hoe het werkt...</td>\n",
       "      <td>communicatie</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['communicatie_NEG']</td>\n",
       "      <td>['communicatie']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>562</td>\n",
       "      <td>De menselijke maat is een belangrijke succesfa...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>positief</td>\n",
       "      <td>['persoonlijke-aandacht_POS']</td>\n",
       "      <td>['persoonlijke aandacht']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>564</td>\n",
       "      <td>Misschien is het een idee om tijdens de onboar...</td>\n",
       "      <td>communicatie</td>\n",
       "      <td>negatief</td>\n",
       "      <td>['communicatie_NEG']</td>\n",
       "      <td>['communicatie']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>565</td>\n",
       "      <td>Ik ben zeer tevreden met Werkmaatschappij Eind...</td>\n",
       "      <td>persoonlijke aandacht</td>\n",
       "      <td>positief</td>\n",
       "      <td>['persoonlijke-aandacht_POS']</td>\n",
       "      <td>['persoonlijke aandacht']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text   \n",
       "0             0  Betere verdeling van uren het verplicht stoppe...  \\\n",
       "1             1  Zou fijn zijn als ik bezoek zou krijgen van We...   \n",
       "2             3  Meedenken carrire, voorstel betere functies, s...   \n",
       "3             4  Meedenken carrire, voorstel betere functies, s...   \n",
       "4             5  Beetje meer waardering zou top zijn met het ke...   \n",
       "..          ...                                                ...   \n",
       "438         560  Ik heb het idee dat nog heel veel intercedente...   \n",
       "439         561  Er mag wel meer uitgelegd worden hoe het werkt...   \n",
       "440         562  De menselijke maat is een belangrijke succesfa...   \n",
       "441         564  Misschien is het een idee om tijdens de onboar...   \n",
       "442         565  Ik ben zeer tevreden met Werkmaatschappij Eind...   \n",
       "\n",
       "                     label sentiment   \n",
       "0     roosters en planning  negatief  \\\n",
       "1    persoonlijke aandacht  negatief   \n",
       "2    persoonlijke aandacht  negatief   \n",
       "3                  salaris  negatief   \n",
       "4    persoonlijke aandacht  negatief   \n",
       "..                     ...       ...   \n",
       "438  persoonlijke aandacht  negatief   \n",
       "439           communicatie  negatief   \n",
       "440  persoonlijke aandacht  positief   \n",
       "441           communicatie  negatief   \n",
       "442  persoonlijke aandacht  positief   \n",
       "\n",
       "                                common_annotation   \n",
       "0                       ['roosters-planning_NEG']  \\\n",
       "1                   ['persoonlijke-aandacht_NEG']   \n",
       "2    ['persoonlijke-aandacht_NEG', 'salaris_NEG']   \n",
       "3    ['persoonlijke-aandacht_NEG', 'salaris_NEG']   \n",
       "4                   ['persoonlijke-aandacht_NEG']   \n",
       "..                                            ...   \n",
       "438                 ['persoonlijke-aandacht_NEG']   \n",
       "439                          ['communicatie_NEG']   \n",
       "440                 ['persoonlijke-aandacht_POS']   \n",
       "441                          ['communicatie_NEG']   \n",
       "442                 ['persoonlijke-aandacht_POS']   \n",
       "\n",
       "                         clean_annotation  encoded_polarity  predictions   \n",
       "0                ['roosters en planning']                 0            0  \\\n",
       "1               ['persoonlijke aandacht']                 0            0   \n",
       "2    ['persoonlijke aandacht', 'salaris']                 0            0   \n",
       "3    ['persoonlijke aandacht', 'salaris']                 0            1   \n",
       "4               ['persoonlijke aandacht']                 0            0   \n",
       "..                                    ...               ...          ...   \n",
       "438             ['persoonlijke aandacht']                 0            0   \n",
       "439                      ['communicatie']                 0            0   \n",
       "440             ['persoonlijke aandacht']                 1            1   \n",
       "441                      ['communicatie']                 0            0   \n",
       "442             ['persoonlijke aandacht']                 1            0   \n",
       "\n",
       "     targets  gold_label  ...  RobBERT_fewDA_label  BERTje_fewDA_label   \n",
       "0          0           0  ...                    0                   1  \\\n",
       "1          0           0  ...                    0                   0   \n",
       "2          0           0  ...                    0                   0   \n",
       "3          0           0  ...                    0                   0   \n",
       "4          0           0  ...                    0                   0   \n",
       "..       ...         ...  ...                  ...                 ...   \n",
       "438        0           0  ...                    0                   0   \n",
       "439        1           0  ...                    0                   0   \n",
       "440        1           1  ...                    0                   0   \n",
       "441        0           0  ...                    0                   0   \n",
       "442        0           1  ...                    0                   0   \n",
       "\n",
       "     RobBERTfew_label_binary  SVM_label_binary  BERTjefew_label_binary   \n",
       "0                          1                 1                       1  \\\n",
       "1                          1                 1                       1   \n",
       "2                          1                 1                       1   \n",
       "3                          0                 1                       1   \n",
       "4                          1                 1                       1   \n",
       "..                       ...               ...                     ...   \n",
       "438                        1                 0                       1   \n",
       "439                        1                 1                       1   \n",
       "440                        1                 0                       0   \n",
       "441                        1                 1                       1   \n",
       "442                        0                 1                       0   \n",
       "\n",
       "     MLP_label_binary  RobBERTzero_label_binary  BERTjezero_label_binary   \n",
       "0                   1                         0                        0  \\\n",
       "1                   1                         1                        0   \n",
       "2                   1                         0                        0   \n",
       "3                   1                         0                        0   \n",
       "4                   1                         1                        0   \n",
       "..                ...                       ...                      ...   \n",
       "438                 1                         1                        0   \n",
       "439                 1                         0                        0   \n",
       "440                 0                         0                        1   \n",
       "441                 1                         1                        0   \n",
       "442                 0                         0                        1   \n",
       "\n",
       "     RobBERT_fewDA_label_binary  BERTje_fewDA_label_binary  \n",
       "0                             1                          0  \n",
       "1                             1                          1  \n",
       "2                             1                          1  \n",
       "3                             1                          1  \n",
       "4                             1                          1  \n",
       "..                          ...                        ...  \n",
       "438                           1                          1  \n",
       "439                           1                          1  \n",
       "440                           0                          0  \n",
       "441                           1                          1  \n",
       "442                           0                          0  \n",
       "\n",
       "[443 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "836b49f4-5703-4bdb-b2fb-6131290a287f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 69.0\n",
      "p-value: 0.2916544513344335\n",
      "\n",
      "McNemar's test statistic: 73.0\n",
      "p-value: 1.1027112080165591e-22\n",
      "\n",
      "McNemar's test statistic: 79.0\n",
      "p-value: 5.4544656666487084e-06\n",
      "\n",
      "McNemar's test statistic: 32.0\n",
      "p-value: 7.793986201015429e-11\n",
      "\n",
      "McNemar's test statistic: 29.0\n",
      "p-value: 1.4292764071780264e-09\n",
      "\n",
      "McNemar's test statistic: 27.0\n",
      "p-value: 1.4874493889233367e-14\n",
      "\n",
      "McNemar's test statistic: 27.0\n",
      "p-value: 1.1331322341928529e-12\n",
      "\n",
      "McNemar's test statistic: 58.0\n",
      "p-value: 0.051523568581622346\n",
      "\n",
      "McNemar's test statistic: 63.0\n",
      "p-value: 0.6030463891288799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_mcnemar_test(series1, series2):\n",
    "    # Create a contingency table\n",
    "    a = sum((series1 == 1) & (series2 == 1))\n",
    "    b = sum((series1 == 0) & (series2 == 1))\n",
    "    c = sum((series1 == 1) & (series2 == 0))\n",
    "    d = sum((series1 == 0) & (series2 == 0))\n",
    "    contingency_table = [[a, b], [c, d]]\n",
    "\n",
    "    # Perform McNemar's test\n",
    "    result = mcnemar(contingency_table)\n",
    "\n",
    "    # Print the test statistic and p-value\n",
    "    print(\"McNemar's test statistic:\", result.statistic)\n",
    "    print(\"p-value:\", result.pvalue)\n",
    "    print()\n",
    "# Example usage:\n",
    "# Assuming you have two Series: series1 and series2\n",
    "perform_mcnemar_test(df_sent['BERTjefew_label_binary'], df_sent['RobBERTfew_label_binary'])\n",
    "perform_mcnemar_test(df_sent['BERTjefew_label_binary'], df_sent['BERTjezero_label_binary'])\n",
    "perform_mcnemar_test(df_sent['RobBERTfew_label_binary'], df_sent['RobBERTzero_label_binary'])\n",
    "perform_mcnemar_test(df_sent['BERTjefew_label_binary'], df_sent['SVM_label_binary'])\n",
    "perform_mcnemar_test(df_sent['BERTjefew_label_binary'], df_sent['MLP_label_binary'])\n",
    "perform_mcnemar_test(df_sent['RobBERTfew_label_binary'], df_sent['SVM_label_binary'])\n",
    "perform_mcnemar_test(df_sent['RobBERTfew_label_binary'], df_sent['MLP_label_binary'])\n",
    "perform_mcnemar_test(df_sent['RobBERTfew_label_binary'], df_sent['RobBERT_fewDA_label_binary'])\n",
    "perform_mcnemar_test(df_sent['BERTjefew_label_binary'], df_sent['BERTje_fewDA_label_binary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d282ebf-50f8-4263-aff3-bed9f8561603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
